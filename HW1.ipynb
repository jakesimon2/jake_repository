{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DoO-oCQXottz"
   },
   "source": [
    "# Homework 1\n",
    "\n",
    "## Jake Simon\n",
    "\n",
    "**DUE OCT 27th by 11:59PM**\n",
    "\n",
    "Homework 1 is done in Jupyter Notebook to give you a chance to familiarize yourself to this powerful tool for data analysis. \n",
    "\n",
    "In Jupyter Notebook, codes and texts are executed in cells. Texts are written in Markdown cell, as you can see in the homework instructions below. Codes are written in code cells. Cells are run one at a time. You can change the cell type by navigating to Cell -> Cell Type.\n",
    "\n",
    "There are spaces for you to enter your answers to the questions, either in code or text. Feel free to add more cells if you need (likely).\n",
    "\n",
    "In many parts, some Scikit-learn functions and classes have already been imported to give you leads on what you may need to use. You still need to refer to the Scikit-learn documentation to learn how the classes and methods work. You can use other publicly available libraries and packages if you want, as long as they finish the work. \n",
    "\n",
    "You are expected to turn in a **pdf version** of this notebook with all your **codes, results, and figures**. Make sure the figures and results are visible as you want them to appear in the pdf before turning it in. Please do not modify the instructions as doing so will limit our ability to follow and grade your answers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9QnIt4o0qmGP"
   },
   "source": [
    "## Problem 1\n",
    "\n",
    "Increase your familiarity with Github. This problem needs to be finished with a partner. Follow these steps to finish the problem:\n",
    "\n",
    "1.   Create a github account.\n",
    "2.   Create a public repository and push a helloworld.py file.\n",
    "3.   Person $A$ forks Person $B$'s repo and modifies the file, then pushes to their own fork and finally creates a pull request for person B to merge.\n",
    "4.   Person $B$ reviews and merges the pull request.\n",
    "5.   Do the same for $A$ and $B$ reversed.\n",
    "\n",
    "Jake's repo: https://github.com/131FinalProject/jake_repository\n",
    "\n",
    "Gavin's repo: https://github.com/131FinalProject/pstat197a_hw1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qKgBcjsyott0"
   },
   "source": [
    "## Problem 2\n",
    "\n",
    "In this problem, you will consider solving the least-squared problem in two different approaches, one using Gradient Descent and the other using the formula. After that, you will compare the results you get from both approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "afphJhGpott1"
   },
   "source": [
    "a) Load the 1-D data and the labels from **'linear_regression.csv'**. The first column contains the data values and the second column contains the labels. Store the data in a variable ***X***. Similarly, store the labels in a variable ***y***."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "nDFz3_7oott1"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression, SGDRegressor\n",
    "\n",
    "X = pd.read_csv('linear_regression.csv', header=None).iloc[:,0].values.reshape(-1,1)\n",
    "y = pd.read_csv('linear_regression.csv', header=None).iloc[:,1].values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3SVBu5DHott3"
   },
   "source": [
    "b) Fit a linear regression model, in the form $Ax + b$, using the formula. Print out the parameters $A$ and $b$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9Fy8FHUHott4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A =  7.526346995925662\n",
      "b =  0.20313216364663322\n"
     ]
    }
   ],
   "source": [
    "lin_reg = LinearRegression()\n",
    "\n",
    "lin_reg.fit(X,y)\n",
    "y_hat = lin_reg.predict(X)\n",
    "\n",
    "# Returns the A and b values from the model\n",
    "A = lin_reg.coef_[0,0]\n",
    "b = lin_reg.intercept_[0]\n",
    "print(\"A = \", A)\n",
    "print(\"b = \", b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ljnZQZS6ott5"
   },
   "source": [
    "Visualize your result in a 2-D plot. Your plot should show the data points and the line $Ax + b$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "8ayp0_6aott6"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X, y)\n",
    "plt.plot(X, y_hat, color=\"#00aa12\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j45fNRvUott8"
   },
   "source": [
    "c) Now, fit a linear regression model using Gradient Descent. Print out the parameters $A$ and $b$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0yeBTn96ott8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A =  4.459047669183188\n",
      "b =  3.312217951201884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jake/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "grad_des = SGDRegressor()\n",
    "\n",
    "grad_des.fit(X,y)\n",
    "y_hat2 = grad_des.predict(X)\n",
    "\n",
    "# Returns the A and b values from the model\n",
    "A2 = grad_des.coef_[0]\n",
    "b2 = grad_des.intercept_[0]\n",
    "print(\"A = \", A2)\n",
    "print(\"b = \", b2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AFyYnKvLott-"
   },
   "source": [
    "Visualize your result in a 2-D plot similar to that in part **b**. Compare your results from both parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "sv2sHAXVott-"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X,y)\n",
    "plt.plot(X, y_hat2, color=\"#dd1400\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:#dd1234\">\n",
    "    \n",
    "Linear regression gives us a higher slope (coefficent), but a lower intercept, while gradient descent gives us a higher intercept, but a lower slope (coefficent). Since linear regression takes sum of squares into account when calculating slope, the slope could be more exaggerated based on the outliers on both x and y-axes. Since gradient descent calculates weight scores for its training data, its slope would be less exaggerated by maxima and minima from the x and y-axes, causing its intercept to be closer to the mean and the slope to have a smaller magnitude to match the data cluster.\n",
    "\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pJjfeIAuotuA"
   },
   "source": [
    "## Problem 3\n",
    "\n",
    "In this problem, you will train classifiers using two widely used algorithms, Support Vector Machine (SVM) and Random Forest (RF). You will train and fine-tune each model using cross-validation (CV). After that, you will compare the performance of SVM and RF for this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "34BoVBR3otuA"
   },
   "source": [
    "a) A 13-D dataset with labels is given in **'wine.csv'**. The last column contains the labels. Store the data and the labels in variables ***X*** and ***y***, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "SRn_EaZqotuB"
   },
   "outputs": [],
   "source": [
    "X = pd.read_csv('wine.csv', header=None).iloc[:,0:13].values # REMEMBER: Python stores indices from 0 to 13-1\n",
    "y = pd.read_csv('wine.csv', header=None).iloc[:,13].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XhA84qMtotuD"
   },
   "source": [
    "Split the data into a train set and a test set. The size of the train set is 90% of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "w-rLDnz2otuD"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XzmsEV8HotuF"
   },
   "source": [
    "b) Find a good SVM model by performing 10-fold CV on the train set. Try different set of model parameters and record the resulting model performance during CV. Print out your best model's parameters and its performance (accuracy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "UkOVB_IKotuF"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jake/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boost Classifier mean test score = 0.95625\n",
      "SVC mean test score = 0.9625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jake/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# A few methods to get you started with CV. \n",
    "# You are encouraged to look into the model_selection module of Scikit-learn to find tools that best fit your need.\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV, ParameterGrid\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# ~~~~~ Gradient Boost Classifier ~~~~~\n",
    "grs_pars = {}\n",
    "gbc = GradientBoostingClassifier()\n",
    "grs = GridSearchCV(gbc, grs_pars, cv=10)\n",
    "\n",
    "grs.fit(Xtrain, Ytrain)\n",
    "print(\"Gradient Boost Classifier mean test score =\", grs.cv_results_['mean_test_score'].max())\n",
    "\n",
    "# ~~~~~ SVC ~~~~~\n",
    "srs_pars = {'kernel':['linear'], 'gamma':['auto']}\n",
    "svc = SVC()\n",
    "srs = GridSearchCV(svc, srs_pars, cv=10)\n",
    "\n",
    "srs.fit(Xtrain, Ytrain)\n",
    "print(\"SVC mean test score =\", srs.cv_results_['mean_test_score'].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QftYtzFW-i0E"
   },
   "source": [
    "Now train your best SVM model on the whole train dataset and test it on the test set. Print out your model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "9qCn-sLV_Zhc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy = 0.94444\n"
     ]
    }
   ],
   "source": [
    "Yhat = srs.predict(Xtest)\n",
    "print(\"Test accuracy = %.5f\" % accuracy_score(Ytest, Yhat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mTsl_Cc8otuH"
   },
   "source": [
    "c) Similarly, find a good RF model by performing 10-fold CV on the train set. Print out your best model's parameters and its performance (accuracy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "bzWFF9MvotuH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier mean test score = 0.94375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jake/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier()\n",
    "rfc_pars = {'n_estimators':[10], 'max_depth':[3], 'random_state':[0]}\n",
    "rrs = GridSearchCV(rfc, rfc_pars, cv=10)\n",
    "\n",
    "rrs.fit(Xtrain, Ytrain)\n",
    "print(\"Random Forest Classifier mean test score =\", rrs.cv_results_['mean_test_score'].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5mfjPPRK_do8"
   },
   "source": [
    "Test your best RF model on the test set. Print out your model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "35f4P7h2_w61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy = 0.94444\n"
     ]
    }
   ],
   "source": [
    "Yhat_forest = rrs.predict(Xtest)\n",
    "print(\"Test accuracy = %.5f\" % accuracy_score(Ytest, Yhat_forest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QMWu3IBStbRq"
   },
   "source": [
    "d) Compare the 2 models. Why do we need CV?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:#dd1234\">\n",
    "\n",
    "We need cross-validation to make sure our predictions are repeatable and not overfitted. The fewer reptitions used to validate a model, the more likely its accuracy could be overfitted to a single set of training data.\n",
    "\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uac965pmotuL"
   },
   "source": [
    "## Problem 4\n",
    "\n",
    "### Skip for Homework 1; Save for Homework 2\n",
    "\n",
    "In this problem, you will work on the clustering problem using Bottom-up Agglomerative clustering and K-mean clustering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YYox5r6IotuL"
   },
   "source": [
    "a) A 4-D dataset is given in **'iris.csv'** with the last column being the ground truth label. Load the file. Store the data in a variable ***X*** and store the label in a variable ***y***. Because clustering is an unsupervised task, there is no need for the labels during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wf0fueP1otuM"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UzQL_DImotuN"
   },
   "source": [
    "b) Train a clustering model using Bottom-up Agglomerative clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "r90ogg-FotuO"
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fsr5q1nFotuP"
   },
   "source": [
    "Visualize your clusters on a 2-D plot. Choose any 2 dimensions from the 4 dimensions to plot. Try to pick the 2 dimensions that best separate the data. Your plot should contains all the data points with points from the same predicted cluster haveing the same color. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q5gBODR5otuQ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1iEBekEy1SIK"
   },
   "source": [
    "Repeat the visualization step above using the same 2 dimensions. This time, plot according to the ground truth classes. Comment on the performance of your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p3lf0Xrv1w6X"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W9PfTf2sotuR"
   },
   "source": [
    "c) Train a clustering model using K-mean clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "G5qzh74NotuR"
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "htqJKZCrotuT"
   },
   "source": [
    "Visualize your clusters on a 2-D plot. Choose any 2 dimensions from the 4 dimensions to plot. Try to pick the 2 dimensions that best separate the data. Your plot should contains all the data points with points from the same predicted cluster haveing the same color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "deWqhR4potuT"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Da9qg3Wi1358"
   },
   "source": [
    "Repeat the visualization step above using the same 2 dimensions. This time, plot according to the ground truth classes. Comment on the performance of your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z7EgKmxx17_s"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b-8WjIaNotuV"
   },
   "source": [
    "d) Perform Principle Component Analysis (PCA) on the data. Project the original data on the 2 largest principle components. Store this new projected 2-D data in a variable ***X_projected***."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Jnx5i9NwotuV"
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c4VFnvdTotuW"
   },
   "source": [
    "Repeat part **b** on the new 2-D data. Train the Bottom-up Agglomerative model and visualize your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sLhLTY-PotuX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZhXg9gKEotuY"
   },
   "source": [
    "Repeat part **c** on the new 2-D data. Train the K-means model and visualize your result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o8jwbAElotuZ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fz5Wc_dgotua"
   },
   "source": [
    "Compare the quality of 4-D and 2-D clusterings. When would the ideas of projection and dimensionality reduction be useful?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WmsQa5XEHUau"
   },
   "source": [
    "## Problem 5\n",
    "\n",
    "What is the hypothesis space for problems 1-3? What are the pros and cons of having a large hypothesis space? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:#dd1234\">\n",
    "\n",
    "The hypothesis space for problems 1-3 are the splits used by the X variables used to predict the response variable Y.\n",
    "\n",
    "The benefit of having a large hypothesis space is that it can cover many unique data points within the data. For example, points with higher dimensionality will be more likely to be properly classified within a large hypothesis space than in a smaller hypothesis space. In addition, it can be applied to datasets with larger amounts of variables without the worrying of underfitting the data. However, the problem of having a large hypothesis space is that it can easily overfit data and misinterpret test data. For example, if a loan has certain variables that justify its usage, assigning too many hyperparameters to the space will cause similar data points to be classified very differently and take a toll on the prediction's accuracy.\n",
    "\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xYuqFx8xHa1M"
   },
   "source": [
    "## Problem 6\n",
    "\n",
    "Suppose we find the best binary classifier for a set of red points and another binary classifier for a set of blue points. Now, suppose we are given a new set of $R$ red and $B$ blue points that we can predict to be positive or negative. If we have to choose a subset of $k$ positive points from $R$ union $B$, what would be fair way for choosing. \n",
    "\n",
    "You are given a red dataset in 'R.csv' and a blue dataset in 'B.csv'. There is also a third test dataset in 'RBtest.csv'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jFV_vm-orpDp"
   },
   "source": [
    "a) Load the datasets. All datasets are 2-D with the last column containing the labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "FZBjsepYHf5P"
   },
   "outputs": [],
   "source": [
    "Xtrain_r = pd.read_csv(\"R.csv\", header=None).iloc[:,0:2].values\n",
    "Ytrain_r = pd.read_csv(\"R.csv\", header=None).iloc[:,2].values\n",
    "\n",
    "Xtrain_b = pd.read_csv(\"B.csv\", header=None).iloc[:,0:2].values\n",
    "Ytrain_b = pd.read_csv(\"B.csv\", header=None).iloc[:,2].values\n",
    "\n",
    "Xtest_rb = pd.read_csv(\"RBtest.csv\", header=None).iloc[:,0:2].values\n",
    "Ytest_rb = pd.read_csv(\"RBtest.csv\", header=None).iloc[:,2].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RemkSEnPr1IB"
   },
   "source": [
    "b) Train 2 classifiers, one for the red dataset and the other for the blue dataset. You are free to choose the learning algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "oFuY0Y8qsNh-"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jake/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "/Users/jake/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "/Users/jake/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "/Users/jake/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Test Scores for the red training dataset:\n",
      "SVC (Support Vector Classifier): 0.8875\n",
      "Gradient Boost Classifier: 0.8938\n",
      "Random Forest Classifier: 0.8750\n",
      "\n",
      "Mean Test Scores for the blue training dataset:\n",
      "SVC (Support Vector Classifier): 0.8750\n",
      "Gradient Boost Classifier: 0.8562\n",
      "Random Forest Classifier: 0.8625\n"
     ]
    }
   ],
   "source": [
    "# SVC (Support Vector Classifer) method:\n",
    "srs_pars = {'kernel':['linear'], 'gamma':['auto'], 'degree':[2], 'random_state':[0]}\n",
    "svc = SVC()\n",
    "srs = GridSearchCV(svc, srs_pars, cv=10)\n",
    "\n",
    "# Gradient Boost Classifier method:\n",
    "grs_pars = {'n_estimators':[10], 'max_depth':[2], 'random_state':[0]}\n",
    "gbc = GradientBoostingClassifier()\n",
    "grs = GridSearchCV(gbc, grs_pars, cv=10)\n",
    "\n",
    "# Random Forest Classifier method:\n",
    "rfc = RandomForestClassifier()\n",
    "rfc_pars = {'n_estimators':[10], 'max_depth':[2], 'random_state':[0]}\n",
    "rrs = GridSearchCV(rfc, rfc_pars, cv=10)\n",
    "\n",
    "# Fit methods to the red training dataset:\n",
    "srs.fit(Xtrain_r, Ytrain_r)\n",
    "grs.fit(Xtrain_r, Ytrain_r)\n",
    "rrs.fit(Xtrain_r, Ytrain_r)\n",
    "\n",
    "print(\"Mean Test Scores for the red training dataset:\")\n",
    "print(\"SVC (Support Vector Classifier): %.4f\" % srs.cv_results_['mean_test_score'].max())\n",
    "print(\"Gradient Boost Classifier: %.4f\" % grs.cv_results_['mean_test_score'].max())\n",
    "print(\"Random Forest Classifier: %.4f\" % rrs.cv_results_['mean_test_score'].max())\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "# Fit methods to the red training dataset:\n",
    "srs.fit(Xtrain_b, Ytrain_b)\n",
    "grs.fit(Xtrain_b, Ytrain_b)\n",
    "rrs.fit(Xtrain_b, Ytrain_b)\n",
    "\n",
    "print(\"Mean Test Scores for the blue training dataset:\")\n",
    "print(\"SVC (Support Vector Classifier): %.4f\" % srs.cv_results_['mean_test_score'].max())\n",
    "print(\"Gradient Boost Classifier: %.4f\" % grs.cv_results_['mean_test_score'].max())\n",
    "print(\"Random Forest Classifier: %.4f\" % rrs.cv_results_['mean_test_score'].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bRp8Q1g6sQZW"
   },
   "source": [
    "c) Now use your models to classify instances in the test dataset. The models may agree on many points but may also disagree on many other points. Let's call the set of positive points classified by the red model $P_r$ and the set of positive points classified by the blue model $P_b$. You are asked to pick out $k$ points from the set $P_r \\cup P_b$. What is a fair way to do this? Demonstrate your answer with code and visualizations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "INVo2ChrtSOm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy using red's best classifier = 0.85000\n",
      "Test accuracy using blue's best classifier = 0.90000\n"
     ]
    }
   ],
   "source": [
    "Yhat_rb = grs.predict(Xtest_rb)\n",
    "print(\"Test accuracy using red's best classifier = %.5f\" % accuracy_score(Ytest_rb, Yhat_rb))\n",
    "Yhat_rb = srs.predict(Xtest_rb)\n",
    "print(\"Test accuracy using blue's best classifier = %.5f\" % accuracy_score(Ytest_rb, Yhat_rb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "HW1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
